apiVersion: v1
kind: ConfigMap
metadata:
  name: alerting-rules-config
data:
  alertingRules.yml: |-
    # This is where the content of the 'alertingRules.yml' starts
    groups:
    - name: Service Availability
      interval: 1m
      rules:

      - alert: DatabaseDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="stateful_mongo-server"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Database (MongoDB) is down.
          description: Database (MongoDB) has been down for the last 5 minutes. No container of the service is running.
    
      - alert: RabbitMQDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="stateful_rabbitmq"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: RabbitMQ is down.
          description: RabbitMQ has been down for the last 5 minutes. No container of the service is running.

      - alert: RedisDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="stateful_redis"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Redis is down.
          description: Redis has been down for the last 5 minutes. No container of the service is running.

      - alert: RedisPersistentDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="stateful_redis-persistent"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Redis persistent is down.
          description: Redis persistent has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_DE_TRAIN Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-train-DE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-train-DE is down.
          description: Service nlp-train-DE has been down for the last 5 minutes. No container of the service is running.
      
      - alert: NLP_DE_SCORE Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-score-DE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-score-DE is down.
          description: Service nlp-score-DE has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_DE_TOKENS Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-tokens-DE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-tokens-DE is down.
          description: Service nlp-tokens-DE has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_EN_TRAIN Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-train-EN"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-train-EN is down.
          description: Service nlp-train-EN has been down for the last 5 minutes. No container of the service is running.
      
      - alert: NLP_EN_SCORE Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-score-EN"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-score-EN is down.
          description: Service nlp-score-EN has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_EN_TOKENS Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-tokens-EN"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-tokens-EN is down.
          description: Service nlp-tokens-EN has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_GE_TRAIN Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-train-GE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-train-GE is down.
          description: Service nlp-train-GE has been down for the last 5 minutes. No container of the service is running.
      
      - alert: NLP_GE_SCORE Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-score-GE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-score-GE is down.
          description: Service nlp-score-GE has been down for the last 5 minutes. No container of the service is running.

      - alert: NLP_GE_TOKENS Down
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-nlp-tokens-GE"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service nlp-tokens-GE is down.
          description: Service nlp-tokens-GE has been down for the last 5 minutes. No container of the service is running.
      
      - alert: FlowsDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-flows"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service Flows is down.
          description: Service Flows has been down for the last 5 minutes. No container of the service is running.
    
      - alert: EndpointDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-endpoint"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service Endpoint is down.
          description: Service Endpoint has been down for the last 5 minutes. No container of the service is running.

      - alert: AIDown
        expr: absent(count(container_last_seen{container_label_com_docker_swarm_service_name="cognigy_service-ai"})) == 1
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Service AI is down.
          description: Service AI has been down for the last 5 minutes. No container of the service is running.

      - alert: QueueTimeout
        expr: increase(cognigy_rpc_timeout_total[5m]) > 5
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Queue {{ $labels.queue }} is experiencing timeouts
          description: Queue {{ $labels.queue_name }} is experiencing timeouts for the payload type {{ $labels.payload_type }}. The current amount of timeouts is {{ $value }}

      - alert: QueueResponseTime
        expr: sum(cognigy_rpc_duration_seconds_sum) / sum(cognigy_rpc_duration_seconds_count) > 2
        for: 5m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          summary: Queue {{ $labels.queue_name }} is slow
          description: Queue {{ $labels.queue_name }} has an average response time of {{ $value }} with the payload {{ $labels.payload_type }}

      # - alert: ServiceRestarts
      #   expr: delta(service:container_state_change[10m]) < 0
      #   for: 5m
      #   labels:
      #     severity: email
      #     hostname: <HOST>
      #   annotations:
      #     summary: Service {{ $labels.container_label_com_docker_swarm_service_nam }} is restarting
      #     description: Service {{ $labels.container_label_com_docker_swarm_service_nam }} has an average change in replica count of {{ $value }}


    # - name: RabbitMQ Alerting
    #   rules:
    #   - alert: UnacklowedgedMessages
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     expr: rabbitmq_queue_messages_unacknowledged{queue!~"nlp-\\w{2}-train_v2"} > 0
    #     for: 5m
    #     annotations:
    #       summary: Queue {{ $labels.queue }} has unacklowedged messages.
    #       description: Queue {{ $labels.queue_name }} has {{ $value }} unacklowedged messages.

    #   - alert: UnacklowedgedMessagesNLP
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     expr: rabbitmq_queue_messages_unacknowledged{queue=~"nlp-\\w{2}-train_v2"} > 0
    #     for: 10m
    #     annotations:
    #       summary: Queue {{ $labels.queue }} has unacklowedged messages.
    #       description: Queue {{ $labels.queue_name }} has {{ $value }} unacklowedged messages.

    #   - alert: ReadyMessages
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     expr: rabbitmq_queue_messages_ready > 5
    #     for: 5m
    #     annotations:
    #       summary: Queue {{ $labels.queue }} has ready messages.
    #       description: Queue {{ $labels.queue_name }} has {{ $value }} ready messages that are not being processed.

    #   - alert: NoConsumers
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     expr: rabbitmq_queue_consumers == 0
    #     for: 5m
    #     annotations:
    #       summary: Queue {{ $labels.queue }} has no consumers.

    # - name: Disk Space
    #   rules:
    #   - alert: PreditciveHostDiskSpace
    #     expr: predict_linear(node_filesystem_free{mountpoint="/"}[48h], 4 * 3600) < 0
    #     for: 30m
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     annotations:
    #       description: 'Based on recent sampling, the disk is likely to be full
    #         within the next 48 hours for instace: {{ $labels.instance_id
    #         }} tagged as: {{ $labels.instance_name_tag }}'
    #       summary: Predictive Disk Space Utilisation Alert

    - name: Prometheus Availability
      rules:
      - alert: PrometheusIngestionThrottling
        expr: prometheus_local_storage_persistence_urgency_score > 0.95
        for: 1m
        labels:
          severity: email
          hostname: <HOST>
        annotations:
          description: Prometheus cannot persist chunks to disk fast enough. It's urgency
            value is {{$value}}.
          summary: Prometheus is (or borderline) throttling ingestion of metrics

    # - name: CPU
    #   rules:
    #   - alert: HostCPUUtilisation
    #     expr: 100 - (avg by(instance) (irate(node_cpu{mode="idle"}[5m])) * 100) > 70
    #     for: 20m
    #     labels:
    #       severity: email
    #       hostname: <HOST>
    #     annotations:
    #       description: 'High CPU utilisation detected for instance {{ $labels.instance_id
    #         }} tagged as: {{ $labels.instance_name_tag }}. The utilisation is currently:
    #         {{ $value }}%'
    #       summary: CPU Utilisation Alert