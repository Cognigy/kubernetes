apiVersion: apps/v1
kind: Deployment
metadata:
    name: service-nlp-tokens-de
spec:
    selector:
        matchLabels:
            app: service-nlp-tokens-de
    replicas: 1
    template:
        metadata:
            labels:
                app: service-nlp-tokens-de
        spec:
            containers:
            - name: service-nlp-tokens-de
              image: docker.cognigy.com:5000/service-nlp-tokens:dd049a1f1b3c19df4a1c94af945c299796e28966
              resources:
                limits:
                    memory: "500Mi"
                    cpu: "500m"
                requests:
                    memory: "300Mi"
                    cpu: "500m"
              # mount persistent volume claim for nlp config and models
              volumeMounts:
              - name: nlp-models-nfs
                mountPath: /data/models
              - name: languages-config
                mountPath: /languages
              - name: rabbitmq-connection-string
                # This will mount the file in /run/secrets. Alpine Linux bug
                mountPath: /var/run/secrets
              envFrom:
                - configMapRef:
                    name: cognigy-env
              env:
              - name: LANGUAGES_TO_RUN
                value: de-DE
              - name: LANGUAGE_CONFIG_PATH
                value: /languages/languages.json
            volumes:
            - name: nlp-models-nfs
              persistentVolumeClaim:
                claimName: nlp-models-nfs
            - name: languages-config
              configMap:
                name: languages-config
            - name: rabbitmq-connection-string
              secret:
                secretName: cognigy-rabbitmq
                items:
                  - key: connection-string
                    path: rabbitmqConnectionString
            imagePullSecrets:
            - name: cognigy-registry-token