apiVersion: apps/v1
kind: Deployment
metadata:
    name: service-nlp-tokens-ge
spec:
    selector:
        matchLabels:
            app: service-nlp-tokens-ge
    replicas: 1
    template:
        metadata:
            labels:
                app: service-nlp-tokens-ge
        spec:
            containers:
            - name: service-nlp-tokens-ge
              image: docker.cognigy.com:5000/service-nlp-tokens:59ab503ee3c18e32533c65f66ee559c3a19ca99d
              resources:
                limits:
                    memory: "2Gi"
                    cpu: "500m"
                requests:
                    memory: "1.5Gi"
                    cpu: "500m"
              # mount persistent volume claim for nlp config and models
              volumeMounts:
              - name: nlp-models-nfs
                mountPath: /data/models
              - name: languages-config
                mountPath: /languages
              - name: rabbitmq-connection-string
                # This will mount the file in /run/secrets. Alpine Linux bug
                mountPath: /var/run/secrets
              envFrom:
                - configMapRef:
                    name: cognigy-env
              env:
              - name: LANGUAGES_TO_RUN
                value: ja-JP,da-DK,es-ES,nl-NL,zh-CN
              - name: LANGUAGE_CONFIG_PATH
                value: /languages
            volumes:
            - name: nlp-models-nfs
              persistentVolumeClaim:
                claimName: nlp-models-nfs
            - name: languages-config
              configMap:
                name: languages-config
            - name: rabbitmq-connection-string
              secret:
                secretName: cognigy-rabbitmq
                items:
                  - key: connection-string
                    path: rabbitmqConnectionString
            imagePullSecrets:
            - name: cognigy-registry-token